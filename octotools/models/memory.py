# octotools/models/memory.py
from typing import Dict, Any, List, Union, Optional
import os
from datetime import datetime

from octotools.models.semantic import SemanticCodeFragment
from octotools.models.semantic_types import SemanticTypes

class Memory:
    """å‡çº§ç‰ˆå†…å­˜ç®¡ç†å™¨ - è¯­ä¹‰æ„ŸçŸ¥ + å‘åŽå…¼å®¹"""

    def __init__(self):
        self.query: Optional[str] = None
        self.files: List[Dict[str, str]] = []
        
        # åŽŸæœ‰çš„actionsï¼ˆå‘åŽå…¼å®¹ï¼‰
        self.actions: Dict[str, Dict[str, Any]] = {}
        
        # æ–°å¢žï¼šè¯­ä¹‰åŒ–å­˜å‚¨
        self.semantic_fragments: Dict[str, SemanticCodeFragment] = {}
        self.semantic_workflow: List[str] = []  # è®°å½•è¯­ä¹‰ç±»åž‹çš„æ‰§è¡Œé¡ºåº
        self.workflow_progress: Dict[str, bool] = {}
        
        # åˆå§‹åŒ–é»˜è®¤å·¥ä½œæµçŠ¶æ€
        self._init_workflow_progress()

    def _init_workflow_progress(self):
        """åˆå§‹åŒ–å·¥ä½œæµè¿›åº¦è¿½è¸ª"""
        for semantic_type in SemanticTypes.DEPENDENCIES.keys():
            self.workflow_progress[semantic_type] = False

    # ===== å‘åŽå…¼å®¹ï¼šåŽŸæœ‰æ–¹æ³• =====
    
    def set_query(self, query: str) -> None:
        """è®¾ç½®æŸ¥è¯¢ï¼ˆä¿æŒåŽŸæŽ¥å£ï¼‰"""
        if not isinstance(query, str):
            raise TypeError("Query must be a string")
        self.query = query

    def add_file(self, file_name: Union[str, List[str]], description: Union[str, List[str], None] = None) -> None:
        """æ·»åŠ æ–‡ä»¶ï¼ˆä¿æŒåŽŸé€»è¾‘ï¼‰"""
        if isinstance(file_name, str):
            file_name = [file_name]
        
        if description is None:
            description = [self._get_default_description(fname) for fname in file_name]
        elif isinstance(description, str):
            description = [description]
        
        if len(file_name) != len(description):
            raise ValueError("The number of files and descriptions must match.")
        
        for fname, desc in zip(file_name, description):
            self.files.append({
                'file_name': fname,
                'description': desc
            })

    def add_action(self, step_count: int, tool_name: str, sub_goal: str, command: str, result: Any) -> None:
        """æ·»åŠ actionï¼ˆä¿æŒåŽŸæŽ¥å£ï¼Œä½†å¢žå¼ºè¯­ä¹‰å¤„ç†ï¼‰"""
        action = {
            'tool_name': tool_name,
            'sub_goal': sub_goal,
            'command': command,
            'result': result,
        }
        step_name = f"Action Step {step_count}"
        self.actions[step_name] = action
        
        # æ–°å¢žï¼šå°è¯•ä»Žresultä¸­æå–è¯­ä¹‰ç‰‡æ®µ
        if isinstance(result, list) and len(result) > 0:
            if isinstance(result[0], SemanticCodeFragment):
                self.add_semantic_fragment(result[0], step_count, tool_name, sub_goal)

    def get_query(self) -> Optional[str]:
        """èŽ·å–æŸ¥è¯¢ï¼ˆä¿æŒåŽŸæŽ¥å£ï¼‰"""
        return self.query

    def get_files(self) -> List[Dict[str, str]]:
        """èŽ·å–æ–‡ä»¶ï¼ˆä¿æŒåŽŸæŽ¥å£ï¼‰"""
        return self.files
    
    def get_actions(self) -> Dict[str, Dict[str, Any]]:
        """èŽ·å–actionsï¼ˆä¿æŒåŽŸæŽ¥å£ï¼‰"""
        return self.actions

    # ===== æ–°å¢žï¼šè¯­ä¹‰åŒ–æ–¹æ³• =====
    
    def add_semantic_fragment(self, fragment: SemanticCodeFragment, step_count: int = None, 
                            tool_name: str = None, sub_goal: str = None) -> None:
        """æ·»åŠ è¯­ä¹‰ä»£ç ç‰‡æ®µ"""
        # å­˜å‚¨è¯­ä¹‰ç‰‡æ®µ
        self.semantic_fragments[fragment.semantic_type] = fragment
        
        # æ›´æ–°å·¥ä½œæµè¿›åº¦
        self.workflow_progress[fragment.semantic_type] = True
        
        # è®°å½•æ‰§è¡Œé¡ºåº
        if fragment.semantic_type not in self.semantic_workflow:
            self.semantic_workflow.append(fragment.semantic_type)
        
        # å‘åŽå…¼å®¹ï¼šä¹Ÿæ·»åŠ åˆ°actionsä¸­
        if step_count is not None:
            self.add_action(step_count, tool_name or fragment.tool_source, 
                          sub_goal or f"Generate {fragment.semantic_type} fragment",
                          f"Generated semantic fragment: {fragment.semantic_type}", fragment)

    def get_semantic_fragment(self, semantic_type: str) -> Optional[SemanticCodeFragment]:
        """èŽ·å–ç‰¹å®šç±»åž‹çš„è¯­ä¹‰ç‰‡æ®µ"""
        return self.semantic_fragments.get(semantic_type)

    def get_all_semantic_fragments(self) -> List[SemanticCodeFragment]:
        """èŽ·å–æ‰€æœ‰è¯­ä¹‰ç‰‡æ®µï¼ˆæŒ‰æ‰§è¡Œé¡ºåºï¼‰"""
        fragments = []
        for semantic_type in self.semantic_workflow:
            if semantic_type in self.semantic_fragments:
                fragments.append(self.semantic_fragments[semantic_type])
        return fragments

    def get_semantic_fragments_by_types(self, semantic_types: List[str]) -> List[SemanticCodeFragment]:
        """æŒ‰æŒ‡å®šç±»åž‹èŽ·å–è¯­ä¹‰ç‰‡æ®µ"""
        fragments = []
        for semantic_type in semantic_types:
            if semantic_type in self.semantic_fragments:
                fragments.append(self.semantic_fragments[semantic_type])
        return fragments

    def has_semantic_fragment(self, semantic_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šç±»åž‹çš„è¯­ä¹‰ç‰‡æ®µ"""
        return semantic_type in self.semantic_fragments

    def get_workflow_progress(self) -> Dict[str, bool]:
        """èŽ·å–å·¥ä½œæµè¿›åº¦çŠ¶æ€"""
        return self.workflow_progress.copy()

    def get_completion_percentage(self) -> float:
        """èŽ·å–å®Œæˆç™¾åˆ†æ¯”"""
        completed = sum(1 for completed in self.workflow_progress.values() if completed)
        total = len(self.workflow_progress)
        return (completed / total) * 100 if total > 0 else 0

    def get_next_required_types(self) -> List[str]:
        """èŽ·å–ä¸‹ä¸€æ­¥éœ€è¦çš„è¯­ä¹‰ç±»åž‹ï¼ˆåŸºäºŽä¾èµ–å…³ç³»ï¼‰"""
        completed_types = set(semantic_type for semantic_type, completed 
                            in self.workflow_progress.items() if completed)
        
        next_types = []
        for semantic_type, dependencies in SemanticTypes.DEPENDENCIES.items():
            if semantic_type not in completed_types:
                # æ£€æŸ¥ä¾èµ–æ˜¯å¦éƒ½æ»¡è¶³
                if all(dep in completed_types for dep in dependencies):
                    next_types.append(semantic_type)
        
        return next_types

    def get_missing_dependencies(self, semantic_type: str) -> List[str]:
        """èŽ·å–ç‰¹å®šç±»åž‹ç¼ºå¤±çš„ä¾èµ–"""
        completed_types = set(semantic_type for semantic_type, completed 
                            in self.workflow_progress.items() if completed)
        
        required_deps = SemanticTypes.DEPENDENCIES.get(semantic_type, [])
        missing = [dep for dep in required_deps if dep not in completed_types]
        return missing

    def is_workflow_complete(self, required_types: List[str] = None) -> bool:
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å®Œæˆ"""
        if required_types is None:
            # é»˜è®¤æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´è§£å†³æ–¹æ¡ˆ
            return self.has_semantic_fragment(SemanticTypes.COMPLETE_SOLUTION)
        
        return all(self.has_semantic_fragment(stype) for stype in required_types)

    def get_semantic_summary(self) -> Dict[str, Any]:
        """èŽ·å–è¯­ä¹‰çŠ¶æ€æ‘˜è¦"""
        return {
            "total_fragments": len(self.semantic_fragments),
            "completed_types": list(self.semantic_fragments.keys()),
            "workflow_progress": self.workflow_progress,
            "execution_order": self.semantic_workflow,
            "completion_percentage": self.get_completion_percentage(),
            "next_required": self.get_next_required_types(),
            "is_complete": self.is_workflow_complete()
        }

    def generate_workflow_report(self) -> str:
        """ç”Ÿæˆå·¥ä½œæµè¿›åº¦æŠ¥å‘Š"""
        summary = self.get_semantic_summary()
        
        report_lines = [
            "=== Semantic Workflow Progress ===",
            f"Completion: {summary['completion_percentage']:.1f}%",
            f"Fragments Generated: {summary['total_fragments']}",
            "",
            "Progress by Type:"
        ]
        
        for semantic_type, completed in self.workflow_progress.items():
            status = "âœ…" if completed else "â³"
            dependencies = SemanticTypes.DEPENDENCIES.get(semantic_type, [])
            dep_str = f" (depends on: {dependencies})" if dependencies else ""
            report_lines.append(f"  {status} {semantic_type}{dep_str}")
        
        if summary['next_required']:
            report_lines.extend([
                "",
                f"Next Required: {', '.join(summary['next_required'])}"
            ])
        
        if summary['is_complete']:
            report_lines.extend([
                "",
                "ðŸŽ‰ Workflow Complete! Full solution available."
            ])
        
        return "\n".join(report_lines)

    def export_semantic_fragments(self, output_dir: str = ".") -> str:
        """å¯¼å‡ºæ‰€æœ‰è¯­ä¹‰ç‰‡æ®µä¸ºå•ç‹¬æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_dir = os.path.join(output_dir, f"semantic_fragments_{timestamp}")
        os.makedirs(export_dir, exist_ok=True)
        
        exported_files = []
        for fragment in self.get_all_semantic_fragments():
            filename = f"{fragment.semantic_type}_{fragment.tool_source}.py"
            filepath = os.path.join(export_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"# {fragment.semantic_type.upper()} Fragment\n")
                f.write(f"# Generated by: {fragment.tool_source}\n")
                f.write(f"# Provides: {', '.join(fragment.provides)}\n")
                f.write(f"# Dependencies: {', '.join(fragment.dependencies)}\n\n")
                f.write(fragment.code)
            
            exported_files.append(filepath)
        
        return export_dir

    # ===== è¾…åŠ©æ–¹æ³• =====
    
    def _get_default_description(self, file_name: str) -> str:
        """èŽ·å–æ–‡ä»¶çš„é»˜è®¤æè¿°ï¼ˆä¿æŒåŽŸé€»è¾‘ï¼‰"""
        _, ext = os.path.splitext(file_name)
        ext = ext.lower()

        file_types = {
            'text': ['.txt', '.md'],
            'document': ['.pdf', '.doc', '.docx'],
            'code': ['.py', '.js', '.java', '.cpp', '.h'],
            'data': ['.json', '.csv', '.xml'],
            'spreadsheet': ['.xlsx', '.xls'],
            'presentation': ['.ppt', '.pptx'],
        }
        
        file_type_descriptions = {
            'text': "A text file ({ext} format) containing additional information related to the query",
            'document': "A document ({ext} format) with content relevant to the query",
            'code': "A source code file ({ext} format) potentially related to the query",
            'data': "A data file ({ext} format) containing structured data pertinent to the query",
            'spreadsheet': "A spreadsheet file ({ext} format) with tabular data relevant to the query",
            'presentation': "A presentation file ({ext} format) with slides related to the query",
        }

        for file_type, extensions in file_types.items():
            if ext in extensions:
                return file_type_descriptions[file_type].format(ext=ext[1:])

        return f"A file with {ext[1:]} extension, provided as context for the query"

    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return self.generate_workflow_report()